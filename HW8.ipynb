{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1\n",
    "\n",
    "This conversation explored two supervised machine learning techniques: **Classification Decision Trees** and **Multiple Linear Regression**.\n",
    "\n",
    "*   **Classification Decision Trees** are used for predicting categorical outcome variables, using a tree-like structure of **decision rules** learned from the data. Each node in the tree represents a question about a **predictor variable**, and each branch corresponds to a possible answer.  The final **leaf** nodes provide the predicted **categorical** outcome.\n",
    "\n",
    "    *   Real-world applications include:\n",
    "        *   Medical diagnosis\n",
    "        *   Customer churn prediction\n",
    "        *   Spam filtering\n",
    "        *   Credit risk assessment\n",
    "        *   Fraud detection\n",
    "*   **Multiple Linear Regression (MLR)** predicts **continuous** outcome variables using a linear equation. The equation combines **predictor variables** and their corresponding coefficients.\n",
    "    *   MLR \"learns\" the values of these coefficients during the model-fitting process, minimizing the difference between the predicted and actual outcomes.\n",
    "    *   To make a prediction for new data, the **predictor variable** values are substituted into the fitted linear equation.\n",
    "    *   The sources highlight several important considerations for MLR:\n",
    "        *   **Model Specification:**  Choosing the correct linear form is crucial based on the relationships between the predictor and outcome variables. This involves selecting the types of predictor variables to include, such as continuous, indicator, or interaction variables.\n",
    "        *   **Model Fitting:**  The statsmodels library in Python is commonly used for fitting and analyzing MLR models.\n",
    "        *   **Model Interpretation:**  Understanding the meaning of the coefficients, which represent the average change in the outcome variable for a one-unit increase in the corresponding predictor variable, is essential for interpreting the model.\n",
    "        *   **Model Generalizability:**  Avoiding **overfitting** and ensuring the model can accurately predict outcomes for new data is vital.\n",
    "        *   **Multicollinearity:**  High correlations between **predictor variables** can result in unreliable coefficient estimates and negatively affect the model's generalizability.\n",
    "\n",
    "The conversation emphasized the contrast between **Classification Decision Trees** and **Multiple Linear Regression** in how they make predictions:\n",
    "\n",
    "*   **Multiple Linear Regression:** Predictions are based on a weighted sum of **predictor variables** using a linear equation.\n",
    "*   **Classification Decision Trees:** Predictions are made by traversing the tree structure and applying the **decision rules** at each node, leading to a prediction at the leaf node.\n",
    "\n",
    "Additionally, the conversation touched on:\n",
    "\n",
    "*   **Feature Importance:**  A key aspect of **Decision Trees**, where the contribution of each predictor variable to the model's overall prediction accuracy is quantified.\n",
    "*   **Model Performance Evaluation:**  The importance of evaluating a model's ability to generalize to new, unseen data, using techniques like the **train-test split**, where the data is divided into a training set for model fitting and a testing set for assessing its performance on unseen data.\n",
    "*   **Confusion Matrices:** Tools used to evaluate the performance of classification models, providing insights into the model's accuracy by categorizing predictions as true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "Overall, this conversation explored the fundamentals of two distinct machine learning techniques, highlighting their strengths, weaknesses, and real-world applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e10566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quesiton 2\n",
    "Accuracy could be used in the evaulation of performance of model,\n",
    "as it providing a general sense of its predictive capability.\n",
    "It can be used to quickly compare different models or assess the impact of changes in model parameters.\n",
    "\n",
    "Sensitivity could be used in fraud detection,\n",
    "A model that simply predicts every transaction as legitimate might achieve high accuracy but would be useless in detecting actual fraud.\n",
    "In this scenario,the ability to correctly identify fraudulent transactions becomes crucial,\n",
    "even at the expense of some false positives ,which incorrectly flagging legitimate transactions as fraud.\n",
    "\n",
    "Specificity could be used in detecting a pollen allergy\n",
    "higher specificity is more desirable because a false positive pollen allergy diagnosis\n",
    "might lead to unnecessary avoidance of outdoor activities or the use of medications that could have side effects.\n",
    "high specificity helps ensure that individuals who genuinely don't have the allergy are correctly identified,\n",
    "minimizing the negative impacts of a false positive diagnosis.\n",
    "\n",
    "Precision could be used in spam filtering.\n",
    "In spam filtering, incorrectly classifying an important email as spam can be more problematic than missing a few spam emails.\n",
    "Therefore,the proportion of predicted spam emails that are actually spam should be guaranteed.\n",
    "\n",
    "\n",
    "## A Discussion about Sensitivity, Specificity, and Precision\n",
    "\n",
    "This conversation explored real-world examples of when sensitivity, specificity, and precision are important.  \n",
    "\n",
    "* **Sensitivity** is the proportion of actual positives correctly identified.  It's important when the cost of missing a positive case is high. For example, when testing for a serious disease like cancer, a test with high sensitivity would be preferred to minimize false negatives, even at the cost of some specificity. \n",
    "* **Specificity** is the proportion of actual negatives that are correctly identified.  It's important when the consequences of false positives are significant. For example, in allergy testing, a test with high specificity is crucial to avoid unnecessary lifestyle changes, psychological distress, and medical interventions that might arise from a false positive result. \n",
    "* **Precision** is the proportion of positive identifications that were actually correct. It's important when you want to ensure that the positive predictions made are highly reliable and the cost of false positives is high. For example, a document retrieval system used by a legal firm would prioritize precision to ensure that the documents flagged as relevant are truly useful. \n",
    "\n",
    "The conversation highlighted the trade-offs between these metrics. For example, increasing sensitivity often decreases specificity, and vice versa.  The optimal balance depends on the specific context and the consequences of different types of errors. \n",
    "\n",
    "The sources discuss classification model evaluation and introduce a variety of related metrics, including sensitivity, specificity, and precision, and the conversation used this information to provide real-world examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038701cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "ab_reduced = ab.drop(columns=['Weight_oz', 'Width', 'Height'])\n",
    "ab_reduced_noNaN = ab_reduced.dropna()\n",
    "\n",
    "ab_reduced_noNaN['Pub year'] = ab_reduced_noNaN['Pub year'].astype(int)\n",
    "ab_reduced_noNaN['NumPages'] = ab_reduced_noNaN['NumPages'].astype(int)\n",
    "\n",
    "ab_reduced_noNaN['Hard_or_Paper'] = ab_reduced_noNaN['Hard_or_Paper'].astype('category')\n",
    "\n",
    "print(ab_reduced_noNaN.head())\n",
    "\n",
    "# create `ab_reduced_noNaN` based on the specs above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4 part 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "ab_reduced = ab.drop(columns=['Weight_oz', 'Width', 'Height'])\n",
    "ab_reduced_noNaN = ab_reduced.dropna()\n",
    "\n",
    "ab_reduced_noNaN['Pub year'] = ab_reduced_noNaN['Pub year'].astype(int)\n",
    "ab_reduced_noNaN['NumPages'] = ab_reduced_noNaN['NumPages'].astype(int)\n",
    "\n",
    "ab_reduced_noNaN['Hard_or_Paper'] = ab_reduced_noNaN['Hard_or_Paper'].astype('category')\n",
    "\n",
    "print(ab_reduced_noNaN.head())\n",
    "\n",
    "# create `ab_reduced_noNaN` based on the specs above\n",
    "\n",
    "# Split the data using sample() method\n",
    "np.random.seed(42)\n",
    "ab_reduced_noNaN_train = ab_reduced_noNaN.sample(frac=0.8, replace=False)\n",
    "ab_reduced_noNaN_test = ab_reduced_noNaN.drop(ab_reduced_noNaN_train.index)\n",
    "\n",
    "# Report the number of observations in the training and testing sets\n",
    "print(f\"Training set observations: {len(ab_reduced_noNaN_train)}\")\n",
    "print(f\"Testing set observations: {len(ab_reduced_noNaN_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qustion 4 part 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "ab_reduced = ab.drop(columns=['Weight_oz', 'Width', 'Height'])\n",
    "ab_reduced_noNaN = ab_reduced.dropna()\n",
    "\n",
    "ab_reduced_noNaN['Pub year'] = ab_reduced_noNaN['Pub year'].astype(int)\n",
    "ab_reduced_noNaN['NumPages'] = ab_reduced_noNaN['NumPages'].astype(int)\n",
    "\n",
    "ab_reduced_noNaN['Hard_or_Paper'] = ab_reduced_noNaN['Hard_or_Paper'].astype('category')\n",
    "\n",
    "print(ab_reduced_noNaN.head())\n",
    "\n",
    "# create `ab_reduced_noNaN` based on the specs above\n",
    "\n",
    "# Split the data using sample() method\n",
    "np.random.seed(42)\n",
    "ab_reduced_noNaN_train = ab_reduced_noNaN.sample(frac=0.8, replace=False)\n",
    "ab_reduced_noNaN_test = ab_reduced_noNaN.drop(ab_reduced_noNaN_train.index)\n",
    "\n",
    "# Report the number of observations in the training and testing sets\n",
    "print(f\"Training set observations: {len(ab_reduced_noNaN_train)}\")\n",
    "print(f\"Testing set observations: {len(ab_reduced_noNaN_test)}\")\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree \n",
    "\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "X = ab_reduced_noNaN[['List Price']]\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize the tree\n",
    "tree.plot_tree(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4 chatbot summary\n",
    "This conversation focused on using a decision tree model to predict whether a book is hardcover or paperback based on its list price. The conversation also explored the broader concepts of sensitivity, specificity, and precision in the context of classification model evaluation.\n",
    "\n",
    "**Data Preparation**\n",
    "\n",
    "The conversation began by examining the code for preparing data for a decision tree model in scikit-learn.  The code created a binary indicator variable, *y*, for the outcome (hardcover or paperback) using one-hot encoding on the \"Hard_or_Paper\" variable. The predictor variable, *X*, was defined as the \"List Price\" column. \n",
    "\n",
    "**Building and Training the Model**\n",
    "\n",
    "You then asked for code to train a decision tree classifier with a maximum depth of 2. The code imported the necessary libraries from scikit-learn, initialized the `DecisionTreeClassifier` object, and used the `.fit(X,y)` method to train the model. \n",
    "\n",
    "**Interpreting the Decision Tree**\n",
    "\n",
    "To understand the model's predictions, the conversation focused on interpreting the visualization generated by `tree.plot_tree(clf)`. The conversation explained that this visualization would show a decision tree with a root node based on \"List Price,\" potentially followed by internal nodes for further decisions, and finally leaf nodes indicating the predicted class (hardcover or paperback).   The conversation provided a hypothetical example of how the tree might look and how to interpret the decision rules based on \"List Price\" thresholds.\n",
    "\n",
    "**Sensitivity, Specificity, and Precision**\n",
    "\n",
    "Before moving on to the details of the decision tree, the conversation explored the importance of sensitivity, specificity, and precision in the context of model evaluation.  It provided real-world examples for each metric:\n",
    "\n",
    "* **Sensitivity:**  Crucial in cancer screening to minimize false negatives.\n",
    "* **Specificity:** Important in allergy testing to avoid unnecessary interventions due to false positives.\n",
    "* **Precision:**  Essential in legal document retrieval systems to ensure high reliability of positive predictions.\n",
    "\n",
    "The conversation emphasized the trade-offs between these metrics and how the optimal balance depends on the specific application.\n",
    "\n",
    "**Key Concepts and Insights**\n",
    "\n",
    "This conversation highlighted several key concepts related to decision trees and model evaluation:\n",
    "\n",
    "* **One-Hot Encoding:** Transforming categorical variables into binary (0 or 1) variables for use in machine learning models.\n",
    "* **Decision Tree Structure:** Understanding the components of a decision tree, including root nodes, internal nodes, branches, and leaf nodes, and how they relate to decision rules and predictions. \n",
    "* **Maximum Depth (`max_depth`):** Controlling the complexity of a decision tree by limiting the number of decision levels, affecting the trade-off between model interpretability and the ability to capture complex relationships.\n",
    "* **Classification Model Evaluation:**  Using metrics like sensitivity, specificity, and precision to assess the performance of classification models and understanding the real-world implications of these metrics.\n",
    "* **Trade-offs in Model Evaluation:** Recognizing that optimizing for one metric often comes at the expense of others and that the choice of metrics depends on the specific context.\n",
    "* **Importance of Data Visualization:** Visualizing the decision tree using `tree.plot_tree(clf)` helps to understand how the model makes predictions based on the predictor variable. \n",
    "\n",
    "The sources provide a foundation for this conversation, offering information on decision trees, model evaluation metrics, and related concepts. The conversation expanded on these sources by: \n",
    "\n",
    "* Providing a step-by-step explanation of the code used to prepare the data and train the decision tree model. \n",
    "* Offering a hypothetical example of how to interpret the decision rules based on the visualized decision tree.\n",
    "* Connecting the concepts of sensitivity, specificity, and precision to real-world scenarios, highlighting their importance in practical applications. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qustion 6\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "ab_reduced = ab.drop(columns=['Weight_oz', 'Width', 'Height'])\n",
    "ab_reduced_noNaN = ab_reduced.dropna()\n",
    "\n",
    "ab_reduced_noNaN['Pub year'] = ab_reduced_noNaN['Pub year'].astype(int)\n",
    "ab_reduced_noNaN['NumPages'] = ab_reduced_noNaN['NumPages'].astype(int)\n",
    "\n",
    "ab_reduced_noNaN['Hard_or_Paper'] = ab_reduced_noNaN['Hard_or_Paper'].astype('category')\n",
    "\n",
    "print(ab_reduced_noNaN.head())\n",
    "\n",
    "# create `ab_reduced_noNaN` based on the specs above\n",
    "\n",
    "# Split the data using sample() method\n",
    "np.random.seed(42)\n",
    "ab_reduced_noNaN_train = ab_reduced_noNaN.sample(frac=0.8, replace=False)\n",
    "ab_reduced_noNaN_test = ab_reduced_noNaN.drop(ab_reduced_noNaN_train.index)\n",
    "\n",
    "# Report the number of observations in the training and testing sets\n",
    "print(f\"Training set observations: {len(ab_reduced_noNaN_train)}\")\n",
    "print(f\"Testing set observations: {len(ab_reduced_noNaN_test)}\")\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree \n",
    "\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "X = ab_reduced_noNaN[['List Price']]\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize the tree\n",
    "tree.plot_tree(clf)\n",
    "\n",
    "# Train clf2 with different hyperparameters \n",
    "x = ab_reduced_noNaN[['NumPages', 'Thick', 'List Price']]\n",
    "clf2 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2.fit(x, y)\n",
    "\n",
    "\n",
    "x_test = ab_reduced_noNaN_test[['List Price']]\n",
    "y_test = pd.get_dummies(ab_reduced_noNaN_test[\"Hard_or_Paper\"])['H']\n",
    "\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_pred_clf2 = clf2.predict(x_test)\n",
    "\n",
    "cm_clf = confusion_matrix(y_test, y_pred_clf)\n",
    "cm_clf2 = confusion_matrix(y_test, y_pred_clf2)\n",
    "\n",
    "ConfusionMatrixDisplay(cm_clf).plot(cmap='Blues', values_format='d', display_labels=[\"Paperback\", \"Hardcover\"])\n",
    "ConfusionMatrixDisplay(cm_clf2).plot(cmap='Blues', values_format='d', display_labels=[\"Paperback\", \"Hardcover\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7\n",
    "The differences between the two confusion matrices are primarily due to the features used for training the decision tree classifier. \n",
    "In the first confusion matrix, the model is only trained with the 'List Price' feature,\n",
    "which likely provides a limited understanding of the data, leading to lower predictive performance. \n",
    "In the second confusion matrix, the model is trained with a richer set of features, namely\n",
    "'NumPages', 'Thick', and 'List Price', which enables the classifier to make better-informed decisions, resulting in improved accuracy.\n",
    "\n",
    "The two confusion matrices for clf and clf2 are better because they are trained with a more comprehensive set of features, \n",
    "allowing the models to capture more patterns in the data. Additionally, the max_depth=4 setting likely prevents overfitting \n",
    "by limiting the complexity of the model, which helps maintain generalization and improves the overall predictive performance.\n",
    "\n",
    "### Summary of Confusion Matrix Differences\n",
    "\n",
    "The two confusion matrices you provided are being evaluated on the training dataset, which will make them appear to perform better than they actually do on new data.\n",
    "\n",
    "*   The first confusion matrix is based on a model that only uses the `List Price` variable to predict whether a book will have a long or short lifespan. \n",
    "*   The second confusion matrix uses three predictor variables: `NumPages`, `Thick`, and `List Price`. \n",
    "\n",
    "**Adding more predictor variables allows the model to identify more complex relationships in the data, which can improve its ability to make accurate predictions on new data**. However, using too many predictor variables can lead to overfitting, where the model learns the training data too well and performs poorly on new data. \n",
    "\n",
    "**To get a more accurate assessment of a model's performance, it's important to evaluate it on a separate test dataset that was not used for training**. This is known as \"out-of-sample\" evaluation, and it helps to determine how well the model generalizes to new data. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
